## Телеграм-бот для аналитики по видео

Проект реализует Telegram-бота на Python/aiogram с PostgreSQL и LLM.  
Бот принимает вопросы на русском естественном языке и возвращает **одно число** — результат вычисления по данным о видео и их почасовой статистике.

### Архитектура

- **PostgreSQL**: две таблицы
  - `videos`: итоговая статистика по каждому видео.
  - `video_snapshots`: почасовые снапшоты статистики по видео.
- **Python-приложение**:
  - `app/db`: подключение к БД и миграции/загрузка данных.
  - `app/services`: бизнес‑логика и запросы к данным.
  - `app/nlp`: модуль работы с LLM, парсер текстового запроса → структурированное представление.
  - `app/bot`: Telegram-бот на aiogram.
  - `app/config.py`: конфигурация через переменные окружения.

Высокоуровневая схема:

Пользователь → Telegram → aiogram‑бот → LLM (разбор запроса) → сервисы/SQL → одно числовое значение → ответ пользователю.

### Схема данных

**Таблица `videos`**
- `id` — идентификатор видео (PK).
- `creator_id` — идентификатор креатора.
- `video_created_at` — дата и время публикации видео.
- `views_count`, `likes_count`, `comments_count`, `reports_count` — финальные значения метрик.
- `created_at`, `updated_at` — служебные поля.

**Таблица `video_snapshots`**
- `id` — идентификатор снапшота (PK).
- `video_id` — ссылка на `videos.id`.
- `views_count`, `likes_count`, `comments_count`, `reports_count` — текущие значения на момент замера.
- `delta_views_count`, `delta_likes_count`, `delta_comments_count`, `delta_reports_count` — приращения с прошлого замера.
- `created_at` — время замера (раз в час).
- `updated_at` — служебное поле.

### Подход к преобразованию NL → запрос к данным

1. Бот получает от пользователя текстовый запрос на русском.
2. Модуль `app/nlp/parser.py` формирует промпт для LLM:
   - Описывается схема БД (`videos`, `video_snapshots`), типы полей и связи.
   - Перечисляются поддерживаемые типы структурированных запросов (например, `COUNT_VIDEOS`, `COUNT_VIDEOS_BY_CREATOR_DATE_RANGE`, `SUM_VIEWS_GROWTH_ON_DATE` и др.).
   - Даются примеры: текстовый вопрос → ожидаемый JSON-объект с полями `query_type`, датами, идентификаторами и порогами.
   - Отдельно оговаривается, что модель **не должна писать SQL**, а только выбирать один из типов и заполнить параметры.
3. LLM возвращает JSON, который валидируется pydantic‑моделью (например, `ParsedQuery`).
4. Сервис `app/services/dispatcher.py` по полю `query_type` вызывает нужную функцию из `app/services/queries.py`, где инкапсулированы SQL‑запросы.
5. Результат (одно число) отправляется пользователю.

Даты в промпт‑описании нормализуются до формата `YYYY-MM-DD`, чтобы LLM всегда возвращала даты в ISO‑формате, независимо от формулировки пользователя («28 ноября 2025», «с 1 по 5 ноября 2025» и т.п.).

### Используемая LLM и промпт

По умолчанию проект ориентирован на использование публичного API (например, OpenAI):  
- модель уровня `gpt-4o-mini`/аналогичная достаточно мощна для разборов таких запросов.
- ключ передаётся через `OPENAI_API_KEY`.

Структура системного промпта (упрощённо):
- Описание задачи: «Ты помощник, который по русскоязычному запросу возвращает строго JSON без пояснений».
- Подробное описание таблиц `videos` и `video_snapshots`, связи по `video_id`.
- Перечень допустимых `query_type` и требуемых полей для каждого типа.
- Правила работы с датами и диапазонами («с X по Y включительно»).
- Несколько примеров:  
  - «Сколько всего видео есть в системе?» → `{ "query_type": "COUNT_VIDEOS" }`  
  - «Сколько видео у креатора с id 123 вышло с 1 ноября 2025 по 5 ноября 2025 включительно?» → JSON с `query_type`, `creator_id`, `from_date`, `to_date`.  
  - «На сколько просмотров в сумме выросли все видео 28 ноября 2025?» → JSON с типом `SUM_VIEWS_GROWTH_ON_DATE` и полем `date`.

### Переменные окружения

- `TELEGRAM_BOT_TOKEN` — токен Telegram‑бота.
- `OPENAI_API_KEY` — ключ к выбранному LLM‑провайдеру.
- `DB_HOST`, `DB_PORT`, `DB_NAME`, `DB_USER`, `DB_PASSWORD` — настройки подключения к PostgreSQL.

### Запуск с Docker

1. Установите Docker и docker-compose.
2. Создайте файл `.env` или задайте переменные окружения с `TELEGRAM_BOT_TOKEN` и `OPENAI_API_KEY`.
3. Соберите и запустите контейнеры:

```bash
docker-compose up --build
```

4. После старта БД выполните скрипт загрузки JSON (будет реализован в `app/db/load_data.py`; запуск описывается в финальной версии README).

### Локальный запуск (без Docker)

1. Установите Python 3.12+ и PostgreSQL.
2. Создайте виртуальное окружение и установите зависимости:

```bash
pip install -r requirements.txt
```

3. Настройте переменные окружения для подключения к БД и токена бота.
4. Выполните миграции (скрипт/алембик, будет добавлен в директорию `migrations/`).
5. Загрузите JSON‑файл с данными в БД.
6. Запустите бота:

```bash
python -m app.bot.main
```

### Проверка через служебного бота

После деплоя вашего бота и размещения этого репозитория в публичном доступе:

1. Откройте чат с `@rlt_test_checker_bot`.
2. Отправьте команду:

```text
/check @yourbotnickname https://github.com/yourrepo
```

3. Убедитесь, что ваш бот запущен и доступен в Telegram на момент проверки.


